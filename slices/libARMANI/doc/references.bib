@string{SOAVE = "Proc.~of the Workshop on Self-Organization of AdaptiVE behavior
(SOAVE)"}
@string{springer = "Springer Verlag"}
@string{UAI = "Proc.~of the Conf.~on Uncertainty in Artificial Intelligence
(UAI)"}
@string{ICRA = "Proc.~of the IEEE Int.~Conf.~on Robotics \& Automation (ICRA)"}
@string{IJCAI = "Proc.~of the Int.~Conf.~on Artificial Intelligence (IJCAI)"}
@string{ICML = "Proc.~of the Int.~Conf.~on Machine Learning (ICML)"}
@string{ECML = "Proc.~of the European Conf.~on Machine Learning (ECML)"}
@string{AAAI = "Proc.~of the Nat.~Conf.~on Artificial Intelligence
(AAAI)"}
@string{ECAI = "Proc.~of the European Conf.~on Artificial Intelligence
(ECAI)"}
@string{IROS = "Proc.~of the IEEE/RSJ Int.~Conf.~on Intelligent Robots and
Systems (IROS)"}
@string{ICAR = "Proc.~of the Int.~Conf.~on Advanced Robotics (ICAR)"}
@string{CIRA = "Proc.~of the IEEE Int.~Symposium on Computational Intelligence
in Robotics and Automation (CIRA)"}
@string{ieeeram = "IEEE Robotics \& Automation Magazine"}
@string{JAIR = "Journal of Artificial Intelligence Research"}
@string{jras = "Journal of Robotics \& Autonomous Systems"}
@string{ar = "Journal of Autonomous Robots"}
@string{ieeetrans = "{IEEE} Transactions on Robotics and Automation"}
@string{ijrr = "Int.~Journal of Robotics Research"}
@string{ieeepress = "IEEE Computer Society Press"}
@string{addison = "Addison-Wesley Publishing Inc."}
@string{ieeepress = "IEEE Computer Society Press"}
@string{dagstuhl = "Proc.~of the Dagstuhl Seminar on Plan-based Control of
Robotic Agents"}
@string{ECMR  = "Proc.~of the European Conference on Mobile Robots (ECMR)"}
@string{ROBOTICS = "Proc.~of the Int.~Conf.~on Robotics: Science and Systems"}
@string{NIPS = "Proc.~of the Conf.~on Neural Information Processing Systems
(NIPS)"}
@string{ISRR = "Proc. of the Int.~Symposium of Robotics Research (ISRR)"}
@string{EUROS = "Proc. of the European Robotics Symposium"}

@phdthesis{11-lang-phd,
  author  =  {Lang, Tobias},
  title   =  {Planning and Exploration in Stochastic Relational Worlds},
  school  =  {Fachbereich Mathematik und Informatik, Freie Universit\"at
Berlin},
  year    =  {2011},
  pdfurl  =  {http://userpage.fu-berlin.de/tlang/pub/11-lang-phd.pdf},
}


@InProceedings{toussaint:09-icml,
  title   = {Robot Trajectory Optimization using Approximate Inference},
  author  = {Marc Toussaint},
  booktitle = ICML,
  year    = {2009}
}


@InProceedings{zettlemoyer05,
  author =	 {Luke S. Zettlemoyer and Hanna M. Pasula and Leslie Pack
Kaelbling},
  title =	 {Planning Rules in Noisy Stochastic Worlds},
  booktitle =	 AAAI,
  year =	 2005
}


@article{pasula07ai,
 author  = {Hanna M. Pasula and Luke S. Zettlemoyer and Leslie Pack Kaelbling},
 title   = {Learning Symbolic Models of Stochastic Domains},
 journal = {Journal of Artificial Intelligence Research},
 volume  = {29},
 year    = {2007},
  pages = {309-352}
 }



@article{richardson06,
 author  = {Matt Richardson and Pedro Domingos},
 title   = {Markov Logic Networks},
 journal = {Machine Learning},
 volume  = {62},
 year    = {2006},
 pages   = {107--136}
}

@article{dzeroski01ml,
 author  = {S. D\v{z}eroski and L. de Raedt and K. Driessens},
 title   = {Relational reinforcement learning},
 journal = {Machine Learning},
 volume  = {43},
 year    = {2001},
 pages   = {7--52}
}

@article{driessens06ml,
	title={Graph Kernels and {G}aussian Processes for Relational
Reinforcement Learning},
	author={Kurt~Driessens and Jan~Ramon and Thomas~G{\" a}rtner},
	journal={Machine Learning},
	year= {2006}
}


@article{driessensDzeroski04ml,
 author = {Driessens, Kurt and D\v{z}eroski, Sa\v{s}o},
 title = {Integrating Guidance into Relational Reinforcement Learning},
 journal = {Machine Learning},
 volume = {57},
 number = {3},
 year = {2004},
 pages = {271--304},
 doi = {http://dx.doi.org/10.1023/B:MACH.0000039779.47329.3a},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 }




@Article{deraedt03explorations,
author = { L. {De Raedt} and K. Kersting},
title = {{P}robabilistic {L}ogic {L}earning},
journal = {ACM-SIGKDD Explorations: Special issue on Multi-Relational Data
Mining},
editor = { S. D\v{z}eroski and L. {De Raedt}},
year = {2003},
OPTkey = {},
volume = {5},
number = {1},
pages = {31--48}
}

@InCollection{getoor01,
  author       = "Getoor, Lise and Friedman, Nir and Koller, Daphne and Pfeffer,
Avi",
  title        = "Learning Probabilistic Relational Models",
  booktitle    = "Relational Data Mining",
  year         = "2001",
  editor       = "S. D\v{z}eroski and N. Lavrac",
  publisher    = "Springer-Verlag",
}

@incollection{muggleton96,
        AUTHOR = "S.H. Muggleton",
        TITLE = "Stochastic logic programs",
	URL = "http://www.doc.ic.ac.uk/\~shm/Papers/slp.pdf",
        YEAR = 1996,
        EDITOR = "L. de Raedt",
        PAGES = "254--264",
        BOOKTITLE = "Advances in Inductive Logic Programming",
        PUBLISHER = "IOS Press"
}

@inproceedings{ jaeger97relational,
    author = "Manfred Jaeger",
    title = "Relational {Bayesian} Networks",
    pages = "266--273",
    booktitle = "Proceedings of the 13th Conference on Uncertainty in Artificial
Intelligence",
    editor = "Morgan Kaufmann",
    year = 1997,
    url = "citeseer.ist.psu.edu/jaeger97relational.html",
    url = "citeseer.nj.nec.com/jaeger97relational.html" }


@inproceedings{ milch05blog,
	author = "Brian Milch and Bhaskara Marthi and Stuart Russell and David
Sontag and Daniel L. Ong and Andrey Kolobov",
	title = "BLOG: Probabilistic Models with Unknown Objects",
	pages = "1352--1359",
	booktitle = IJCAI,
	year = 2005
}


@InProceedings{cocora06iros,
  title     = {Learning Relational Navigation Policies},
  author    = {Cocora, A. and Kersting, K. and Plagemann, C. and Burgard, W. and
De Raedt, L.},
  booktitle = {Proc.~of the IEEE/RSJ International Conference on
               Intelligent Robots and Systems (IROS)},
  address   = {Beijing, China},
  year      = {2006},
  abstract  = {Navigation is one of the fundamental tasks for a mobile robot.
The majority of path planning approaches has been designed to entirely solve the
given problem from scratch given the current and goal configurations of the
robot. Although these approaches yield highly efficient plans, the computed
policies typically do not transfer to other, similar tasks. We propose to learn
relational decision trees as abstract navigation strategies from example paths.
Relational abstraction has several interesting and important properties. First,
it allows a mobile robot to generalize navigation plans from specific examples
provided by users or exploration. Second, the navigation policy learned in one
environment can be transferred to unknown environments. In several experiments
with real robots in a real environment and in simulated runs, we demonstrate the
usefulness
of our approach.},
  pdfurl    =
{http://www.informatik.uni-freiburg.de/~plagem/bib/cocora06iros.pdf}
}



@techreport{otterlo05rrl,
	author = "M. van Otterlo",
	title = "A Survey of Reinforcement Learning in Relational Domains",
	institution = "CTIT, University of Twente",
	year = "2005"
}

@inproceedings{tadepalli04overview,
	author = {Tadepalli, P. and Givan, R., and Driessens, K.},
	title = {Relational Reinforcement Learning -- an Overview},
	booktitle = {Proceedings of the ICML'04 Workshop on Relational
Reinforcement Learning},
	pages = {1--9},
	year = 2004
}

@inproceedings { kersting04ilp,
author = {K. Kersting and L. {De Raedt}},
title = {Logical Markov Decision Programs and the Convergence of Logical
TD$(\\lambda)$},
year = {2004},
booktitle = {Proceedings of the Fourteenth International Conference on Inductive
Logic Programming (ILP-04},
editor = {A. Srinivasan and R. King and R. Camacho},
publisher = {Springer},
number = {3194},
series = {LNCS},
pages = {180-197},
month = {September 6-8},
address = {Porto, Portugal}
}


@inproceedings{sanner05approx,
	author = {S. Sanner and C. Boutilier},
	title = {Approximate linear programming for first-order MDPs},
	booktitle = UAI,
	year = 2005
}


@inproceedings{sanner06online,
	author = {S. Sanner},
	title = {Online feature discovery in relational reinforcement learning},
	booktitle = {Proc.~of the Open Problems in Statistical Relational
Learning Workshop},
	year = 2006
}


@inproceedings{sanner07approx,
	author = {S. Sanner and C. Boutilier},
	title = {Approximate solution techniques for factored first-order {MDPs}},
	booktitle = {Proc.~of the Int.~Conf.~on Automated Planning and Scheduling
(ICAPS)},
  pages = {288-295},
	year = 2007
}


@InProceedings{ otterlo04reinforcement,
  author = "M. Van Otterlo",
  title = "Reinforcement Learning for Relational MDPs",
  booktitle = {Proceedings of the Annual Machine Learning Conference of Belgium
and the Netherlands},
  year = "2004"
}


@inproceedings{murphy01ff,
 author = {Kevin P. Murphy and Yair Weiss},
 title = {The Factored Frontier Algorithm for Approximate Inference in {DBN}s},
 booktitle = UAI,
 pages = {378-385},
 year = {2001},
 }


@PhdThesis{murphy02phd,
author = {Kevin P. Murphy},
title = {Dynamic {B}ayesian Networks: Representation, Inference and Learning},
school = {UC Berkeley},
year = {2002}
}


@INPROCEEDINGS{toussaint06,
    author = {Marc Toussaint and Amos Storkey},
    title = {Probabilistic inference for solving discrete and continuous state
{M}arkov decision processes},
    booktitle = ICML,
    pages     = {945-952},
    year = {2006}
}

@article{kearns02ss,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {A Sparse Sampling Algorithm for Near-Optimal Planning in
               Large {M}arkov Decision Processes},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  year      = {2002},
  pages     = {193-208},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@ARTICLE{Sanghai05relationaldynamic,
    author = {Sumit Sanghai and Pedro Domingos and Daniel Weld},
    title = {Relational dynamic {B}ayesian networks},
    journal = {Artificial Intelligence Research},
    year = {2005},
    volume = {24},
    pages = {759-797}
}


@INPROCEEDINGS{Kersting00bayesianlogic,
    author = {Kristian Kersting and Luc {de Raedt}},
    title = {Bayesian logic programs},
    booktitle = {Proceedings of the Work-in-Progress Track at the 10th
International Conference on Inductive Logic Programming},
    year = {2000},
    pages = {138--155}
}

@INPROCEEDINGS{Botvinick09,
    author = {Botvinick, M. M. and An, J.},
    title = {Goal-directed decision making in prefrontal cortex: a
computational framework},
    booktitle = {Advances in Neural Information Processing Systems (NIPS)},
    pages = {169-176},
    year = {2009}
}


@Book{puterman94mdp,
author = {Puterman, M. L.},
title = {Markov Decision Processes},
publisher = {Wiley, New York},
year = {1994},
}

@ARTICLE{Boutilier99decision-theoreticplanning,
    author = {Craig Boutilier and Thomas Dean and Steve Hanks},
    title = {Decision-theoretic planning: Structural assumptions and computational leverage},
    journal = {Artificial Intelligence Research},
    year = {1999},
    volume = {11},
    pages = {1--94}
}

@inproceedings{kersting04icml,
 author = {Kristian Kersting and Martijn {van Otterlo} and Luc {de Raedt}},
 title = {Bellman goes relational},
 booktitle = ICML,
 year = {2004},
 pages = {465-472}
}

@INPROCEEDINGS{croonenborghs07ijcai,
    author = {Tom Croonenborghs and Jan Ramon and Hendrik Blockeel and Maurice Bruynooghe},
    title = {Online learning and exploiting relational models in reinforcement learning},
    booktitle = IJCAI,
    pages = {726-731},
    year = {2007}
}

@book{sutton98rl,
	author = {Sutton, Richard  S.  and Barto, Andrew  G. },
	howpublished = {Hardcover},
	keywords = {introduction, reinforcement\_learning, survey},
	month = {March},
	priority = {3},
	publisher = {{The MIT Press}},
	title = {Reinforcement Learning: An Introduction},
	year = {1998}
}

@article{dayan97em,
 author = {Peter Dayan and Geoffrey E. Hinton},
 title = {Using expectation-maximization for reinforcement learning},
 journal = {Neural Computation},
 volume = {9},
 number = {2},
 year = {1997},
 issn = {0899-7667},
 pages = {271--278},
 doi = {http://dx.doi.org/10.1162/neco.1997.9.2.271},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
 }


@inproceedings{attias03,
	author = {H. Attias},
	title = {Planning by probabilistic inference},
	booktitle = {Proc.~of the 9th Int.~Workshop on AI and Statistics},
	year = {2003},
}

@Book{getoor07,
editor = {L. Getoor and B. Taskar},
title = {Introduction to Statistical Relational Learning},
publisher = {MIT Press},
year = {2007},
}

@inproceedings{gardiol07aaai,
 author    = {Gardiol, Natalia H. and Kaelbling, Leslie Pack},
 title     = {Action-Space partitioning for planning},
 booktitle = AAAI,
 pages     = {980-986},
 year      = {2007}
}


@Book{otterlo09,
author = {van Otterlo, M.},
title = {The Logic of Adaptive Behavior},
publisher = {IOS Press, Amsterdam},
year = {2009},
}

@ARTICLE{solo82,
    author = {Solo, V.},
    title = {Smoothing estimation of stochastic processes: Two-filter formulas},
    journal = {IEEE Transactions on Automatic Control},
    year = {1982},
    volume = {27},
    number = {2},
    pages = {473--476}
}

@article{briers04,
       author = {Briers, M. and Doucet, A. and Maskell, S.},
       title = {Smoothing algorithms for state-space models},
       journal = {To appear in Annals of the Institute of Statistical
Mathematics},
      year = {2009},
}

@article{fikes71strips,
       author = {R. Fikes and N. Nilsson},
       title = { STRIPS: a new approach to the application of theorem proving to
problem solving},
       journal = {Artificial Intelligence},
  volume = {2},
  pages = {189-208},
      year = {1971},
}

@INPROCEEDINGS{bout01ijcai,
    author = {Craig Boutilier and Ray Reiter and Bob Price},
    title = {Symbolic Dynamic Programming for First-order {MDPs}},
    booktitle = IJCAI,
    year = {2001},
    pages = {690--700},
}

@article{wang08jair,
 author  = {C. Wang and S. Joshi and R. Khardon},
 title   = {First Order Decision Diagrams for Relational {MDP}s},
 journal = JAIR,
 volume  = {31},
 year    = {2008},
  pages = {431-472}
}

@InProceedings{lang09icml,
  TITLE     = {Approximate Inference for Planning in Stochastic Relational
Worlds},
  AUTHOR    = {Lang, T. and Toussaint, M.},
  BOOKTITLE = ICML,
  YEAR      = {2009},
}

@InProceedings{rintanen08,
  TITLE     = {Regression for classical and nondeterministic planning},
  AUTHOR    = {Jussi Rintanen},
  BOOKTITLE = ECAI,
  pages     = {568-572},
  YEAR      = {2008},
}


@InProceedings{rabiner89,
 author  = {Lawrence R. Rabiner},
 title   = {A Tutorial on Hidden Markov Models and Selected Applications in
Speech Recognition},
 BOOKTITLE = {Proceedings of the IEEE},
 volume  = {31},
 year    = {1989},
  pages = {257-286}
}

@inproceedings{kocsis06uct,
  author    = {Levente Kocsis and Csaba Szepesvari},
  title     = {Bandit based Monte-Carlo planning},
  booktitle = ECML,
  year      = {2006}
}

@PhdThesis{massey99phd,
author = {Bart Massey},
title = {Directions In Planning: Understanding The Flow Of Time In Planning},
school = {University of Oregon},
year = {1999}
}

@InCollection{newell63,
  author       = "Newell, A. and Simon, H.",
  title        = "GPS: A program that simulates human thought",
  booktitle    = "Computers and Thought",
  year         = "1963",
  editor       = "Feigenbaum and Feldman",
  publisher    = "McGraw-Hill, New York",
}

@article{kushmerick95ai,
  author = {N. Kushmerick and S. Hanks and D. Weld},
  journal = {Artificial Intelligence},
  title = {An algorithm for probabilistic planning},
  volume = {78},
  number = {1-2},
  pages = {239--286},
  year = {1995}
}

@article{sanner09,
 author = {Sanner, Scott and Boutilier, Craig},
 title = {Practical solution techniques for first-order {MDP}s},
 journal = {Artificial Intelligence},
 volume = {173},
 number = {5-6},
 year = {2009},
 pages = {748--788},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
 }


@inproceedings{guestrin02icml,
  author    = {Carlos Guestrin and
               Relu Patrascu and
               Dale Schuurmans},
  title     = {Algorithm-Directed Exploration for Model-Based Reinforcement
               Learning in Factored {MDP}s},
  booktitle = ICML,
  year      = {2002},
  pages     = {235-242}
}

@INPROCEEDINGS{kearns99ijcai,
    author = {Michael Kearns and Daphne Koller},
    title = {Efficient Reinforcement Learning in Factored {MDP}s},
    booktitle = IJCAI,
    year = {1999},
    pages = {740--747}
}


@inproceedings{walsh08,
  author    = {Thomas J. Walsh and
               Michael L. Littman},
  title     = {Efficient Learning of Action Schemas and Web-Service
  Descriptions},
  booktitle = AAAI,
  year      = {2008},
  pages     = {714-719}
}

@inproceedings{walsh09,
  author    = {Thomas J. Walsh and Istvan Szita and Carlos Diuk and
               Michael L. Littman},
  title     = {Exploring compact reinforcement-learning representations with
linear regression},
  booktitle = UAI,
  year      = {2009},
}

@inproceedings { kersting08icml,
author = {K. Kersting and K. Driessens},
title = {Non{--}Parametric Policy Gradients: A Unified Treatment of
Propositional and Relational Domains},
year = {2008},
booktitle = {Proceedings of the 25th International Conference on Machine
Learning (ICML 2008)},
month = {July 5{--}9},
}

@INCOLLECTION{thrun92,
  AUTHOR         = {S. Thrun},
  YEAR           = {1992},
  TITLE          = {The Role of Exploration in Learning Control},
  BOOKTITLE      = {Handbook for Intelligent Control: Neural, Fuzzy and 
                    Adaptive Approaches},
  EDITOR         = {D.A. White and D.A. Sofge},
  PUBLISHER      = {Van Nostrand Reinhold},
  ADDRESS        = {Florence, Kentucky 41022}
}

@inproceedings{epshteyn08icml,
  author    = {Arkady Epshteyn and
               Adam Vogel and
               Gerald DeJong},
  title     = {Active reinforcement learning},
  booktitle = ICML,
  year      = {2008},
  pages     = {296-303}
}

@article{brafman02rmax,
  author    = {Ronen I. Brafman and
               Moshe Tennenholtz},
  title     = {R-MAX - A General Polynomial Time Algorithm for Near-Optimal
               Reinforcement Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {3},
  year      = {2002},
  pages     = {213-231}
}


@inproceedings{deshpande07uai,
  author    = {Ashwin Deshpande and
               Brian Milch and
               Luke S. Zettlemoyer and
               Leslie Pack Kaelbling},
  title     = {Learning Probabilistic Relational Dynamics for Multiple
               Tasks},
  booktitle = UAI,
  year      = {2007},
  pages     = {83-92}
}

@article{kearns02e3,
 author = {Kearns, Michael and Singh, Satinder},
 title = {Near-Optimal Reinforcement Learning in Polynomial Time},
 journal = {Machine Learning},
 volume = {49},
 number = {2-3},
 year = {2002},
 pages = {209--232},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 }


@InProceedings{bilgic:nips09-wkshp,
  author       = "Bilgic, Mustafa and Getoor, Lise",
  title        = "Link-based Active Learning",
  booktitle    = "NIPS Workshop on Analyzing Networks and Learning with Graphs",
  year         = "2009",
}


@article{cohn96jair,
 author = {Cohn, David A. and Ghahramani, Zoubin and Jordan, Michael I.},
 title = {Active learning with statistical models},
 journal = JAIR,
 volume = {4},
 number = {1},
 year = {1996},
 pages = {129--145},
 }

@inproceedings{poupart06icml,
 author = {Poupart, Pascal and Vlassis, Nikos and Hoey, Jesse and Regan, Kevin},
 title = {An analytic solution to discrete Bayesian reinforcement learning},
 booktitle = ICML,
 year = {2006},
 pages = {697--704},
 }

@InProceedings{stachniss05rss,
  TITLE =        {Information Gain-based Exploration Using Rao-Blackwellized
Particle Filters},
  AUTHOR =       {Stachniss, C. and Grisetti, G. and Burgard, W.},
  BOOKTITLE =    RSS,
  ADDRESS =      {Cambridge, MA, USA},
  YEAR =         {2005},
  pages  =       {65--72}
}

@InProceedings{kolter2009icml,
  author =    {J. Zico Kolter and Andrew Ng},
  title =     {Near-{Bayesian} Exploration in Polynomial Time},
  booktitle = ICML,
  pages =     {513--520},
  year =      2009,
}

@inproceedings{driessens03icml,
author = "K. Driessens and J. Ramon",
title = "Relational instance based regression for relational reinforcement
learning",
year = "2003",
pages = "123--130",
booktitle = ICML
}


@inproceedings{driessens05icml,
author = "K. Driessens and S. D\v{z}eroski",
title = "Combining model-based and instance-based learning for first-order
regression",
year = "2005",
pages = "193--200",
booktitle = ICML
}


@inproceedings{ramon07ecml,
  author = "J. Ramon and K. Driessens and T. Croonenborghs",
  title = "Transfer Learning in Reinforcement Learning Problems Through Partial
Policy Recycling",
  booktitle = ECML,
  pages = "699--707",
  year = 2007
}

@InProceedings{lang09ecml,
  TITLE     = {Relevance Grounding for Planning in Relational Domains},
  AUTHOR    = {Lang, T. and Toussaint, M.},
  BOOKTITLE = ECML,
  YEAR      = {2009},
  MONTH     = {September},
}

@article{holl06,
  author =      {H{\"o}lldobler, S. and Karabaev, E. and Skvortsova, O.},
   title =      {{FluCaP:} A Heuristic Search Planner for First-Order {MDPs}},
  journal =     {JAIR} ,
  year =        2006,
  volume =      27,
  pages =       {419--439}
}

@article{SannerBo09,
author = "S. Sanner and C. Boutilier",
title = "Practical Solution Techniques for First Order {MDP}s",
journal = {Artificial Intelligence Journal},
volume = 173,
pages = {748-788},
year = 2009
}

@inproceedings{JoshiKh08,
author = "S. Joshi and R. Khardon",
title = "Stochastic Planning with First Order Decision Diagrams",
booktitle = {Proceedings of ICAPS},
year = 2008
}


@book{getoor2007,
title = "A Introduction to Statistical Relational Learning",
publisher = "MIT Press", 
editor = "Lise Getoor and Ben Taskar",
year = "2007"
}

@inproceedings{joshi10icaps,
author = "S. Joshi and K. Kersting and R. Khardon",
title = "Self-Taught Decision Theoretic Planning with First Order Decision
Diagrams",
year = "2010",
booktitle = "Proceedings of ICAPS-10"
}

@inproceedings{bengio09icml,
 author = {Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Collobert, Ronan and
Weston, Jason},
 title = {Curriculum learning},
 booktitle = ICML,
 year = {2009},
 pages = {41--48},
}

@InProceedings{halbritter07rrlgraph,
  author =   {Florian Halbritter and Peter Geibel},
  title =  {Learning Models of Relational {MDP}s Using Graph Kernels},
  booktitle = {Proc.~of the {M}exican {Co}nf.~on {A.}{I.} (MICAI)},
  year =   2007,
  pages = {409-419}
}


@PhdThesis{walsh10phd,
author = {Thomas J. Walsh},
title = {Efficient learning of relational models for sequential decision making},
school = {Rutgers, The State University of New Jersey, New Brunswick, NJ},
year = {2010}
}

@ARTICLE{lang-toussaint-10jair,
    author = {Tobias Lang and Marc Toussaint},
    title = {Planning with Noisy Probabilistic Relational Rules},
    journal = {Journal of Artificial Intelligence Research},
    year = {2010},
    volume = {39},
    pages = {1-49},
    pdfurl = {http://www.jair.org/media/3093/live-3093-5172-jair.pdf},
    abstract = {Noisy probabilistic relational rules are a promising world
model representation for several reasons. They are compact and generalize over
world instantiations. They are usually interpretable and they can be learned
effectively from the action experiences in complex worlds. We investigate
reasoning with such rules
in grounded relational domains. Our algorithms exploit the compactness of rules
for efficient and flexible decision-theoretic planning. As a first approach, we
combine these rules with the Upper Confidence Bounds applied to Trees (UCT)
algorithm based on look-ahead trees. Our second approach converts these rules
into a structured dynamic Bayesian network representation and predicts the
effects of action sequences using approximate inference and beliefs over world
states. We evaluate the effectiveness of our approaches for planning in a 
simulated complex 3D robot manipulation scenario with an articulated manipulator
and realistic physics and in domains of the probabilistic planning competition.
Empirical results show that our methods can solve problems where existing
methods fail.},
}

@misc{ipc08,
  author = {IPPC},
  title = {Sixth {I}nternational {P}lanning {C}ompetition, {U}ncertainty
{P}art},
  year = {2008},
  url           = {http://www.darmstadt.gmd.de/mobile/MPEG7},
  note          = {\url{http://ippc-2008.loria.fr/wiki/index.php/Main\_Page}},
}


@PHDTHESIS {ramon02phd,
AUTHOR = "Ramon, Jan",
TITLE = {{C}lustering and instance based learning in first order logic},
SCHOOL = {Department of Computer Science, K.U.Leuven},
YEAR = {2002},
TYPE = {PHD},
ADDRESS = {Leuven, Belgium},
MONTH = oct
}


@INPROCEEDINGS{Cussens98usingprior,
    author = {James Cussens},
    title = {Using Prior Probabilities and Density Estimation for Relational
Classification},
    booktitle = {In Proceedings of the Inductive Logic Programming
Conference(ILP'98},
    year = {1998},
    pages = {106--115},
    publisher = {Springer}
}


@article{nouri10ml,
 author = {Nouri, Ali and Littman, Michael L.},
 title = {Dimension reduction and its application to model-based exploration in
continuous spaces},
 journal = {Mach. Learn.},
 volume = {81},
 issue = {1},
 month = {October},
 year = {2010},
 pages = {85--98}
}


@article{winridge-kittler-10,
author = {David Windridge and Josef Kittler},
 title = {Perception-Action Learning as an Epistemologically-Consistent Model
   for Self-Updating Cognitive Representation},
 journal = {Brain Inspired Cognitive Systems (special issue), Advances in
Experimental Medicine and Biology},
 volume = {657},
 year = {2010},
 publisher = {Springer}
}


@article{driessens-dzeroski-04-guidance,
 author = {Kurt Driessens and Sao Dzeroski},
 title = {Integrating guidance into relational reinforcement learning},
 journal = {Machine Learning},
 volume = {57},
 pages = {271-304},
 year = {2004},
 publisher = {Springer}
}

@MISC{Roadmap-US-robotics:2009,
author = {Christensen, Henrik},
title = {From Internet to Robotics -- A Roadmap for {US} Robotics},
month = May,
year = {2009},
note          = {\url{http://www.us-robotics.us/reports/CCC\%20Report.pdf}},
 }
