# Maze size:               2x2
# strategy               = utree-value
# epsilon                = 0
# discount               = 0.5
# episodes               = 1
# transitions            = 100
# min training length    = 10
# max training length    = 10000
# training length factor = 1.1
# training length incr.  = 10
# L1 coefficient         = 0.0001
# max tree size          = 10000
# feature complexity     = 2
# 
# Reward 0
#     ACTIVATION_STATE : 0
#     RECEIVE_STATE    : 3
#     TIME_DELAY       : 2
#     reward           : 1
#     activation       : EACH_TIME
# 
# 
# 
# Episode	training_length	feature_n	utree_size	episode_mean_reward
# 
1 	46	0	1	0
1 	33	0	1	0
1 	21	0	1	0
1 	309	0	1	0
1 	76	0	1	0
1 	156	0	1	0
1 	60	0	1	0
1 	93	0	1	0
1 	442	0	11	0.01
1 	112	0	1	0
1 	10	0	1	0
1 	555	0	11	0
1 	239	0	7	0
1 	349	0	9	0
1 	209	0	7	0
1 	133	0	5	0
1 	496	0	9	0
1 	272	0	7	0.01
1 	1058	0	13	0.25
1 	393	0	7	0.01
1 	1440	0	13	0.25
1 	953	0	13	0.25
1 	1594	0	13	0.25
1 	858	0	11	0
1 	1949	0	13	0.25
1 	1763	0	13	0.25
1 	1173	0	17	0.25
1 	620	0	13	0.01
1 	771	0	19	0
1 	692	0	11	0
1 	1300	0	13	0.25
1 	181	0	5	0
1 	2625	0	13	0.25
1 	2153	0	15	0.25
1 	2378	0	13	0.25
1 	2897	0	13	0.25
1 	3525	0	15	0.25
1 	3196	0	19	0.25
1 	3887	0	21	0.25
1 	5205	0	17	0.25
1 	4285	0	21	0.25
1 	4723	0	21	0.25
1 	6318	0	13	0.25
1 	7664	0	13	0.25
1 	5735	0	21	0.25
1 	8440	0	17	0.25
1 	6959	0	21	0.25
1 	9294	0	15	0.25
# Global mean reward 0.125833
