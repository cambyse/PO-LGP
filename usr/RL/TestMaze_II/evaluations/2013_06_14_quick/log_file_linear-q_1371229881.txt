# Maze size:               2x2
# strategy               = linear-q
# epsilon                = 0
# discount               = 0.5
# episodes               = 1
# transitions            = 100
# min training length    = 10
# max training length    = 10000
# training length factor = 1.1
# training length incr.  = 10
# L1 coefficient         = 0.0001
# max tree size          = 10000
# feature complexity     = 2
# 
# Reward 0
#     ACTIVATION_STATE : 0
#     RECEIVE_STATE    : 3
#     TIME_DELAY       : 2
#     reward           : 1
#     activation       : EACH_TIME
# 
# 
# 
# Episode	training_length	feature_n	utree_size	episode_mean_reward
# 
1 	21	0	0	0.05
1 	10	0	0	0
1 	93	0	0	0.04
1 	46	0	0	0
1 	33	0	0	0.01
1 	60	0	0	0
1 	76	0	0	0
1 	112	0	0	0.01
1 	133	0	0	0
1 	156	0	0	0
1 	181	0	0	0.01
1 	209	0	0	0
1 	239	0	0	0.01
1 	272	0	0	0.01
1 	309	0	0	0
1 	349	0	0	0
1 	393	0	0	0.01
1 	442	0	0	0
1 	496	0	0	0
1 	555	0	0	0
1 	620	0	0	0
1 	692	0	0	0
1 	771	0	0	0
1 	858	0	0	0
1 	953	0	0	0
1 	1058	0	0	0
1 	1173	0	0	0.01
1 	1440	0	0	0
1 	1300	0	0	0.01
1 	1594	0	0	0
1 	1763	0	0	0
1 	1949	0	0	0
1 	2153	0	0	0
1 	2378	0	0	0
1 	2897	0	0	0
1 	2625	0	0	0
1 	3525	0	0	0
1 	3196	0	0	0
1 	3887	0	0	0
1 	4285	0	0	0.01
1 	4723	0	0	0.01
1 	5205	0	0	0.01
1 	5735	0	0	0
1 	6318	0	0	0.01
1 	6959	0	0	0
1 	7664	0	0	0
1 	8440	0	0	0
1 	9294	0	0	0
# Global mean reward 0.004375
