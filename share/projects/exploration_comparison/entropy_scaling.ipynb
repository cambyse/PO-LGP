{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "from __future__ import print_function\n",
      "import random\n",
      "import copy\n",
      "import pprint as pp\n",
      "\n",
      "import numpy as np\n",
      "arr = np.array\n",
      "import scipy.stats as ss\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import seaborn as sns\n",
      "\n",
      "import probdist\n",
      "\n",
      "%matplotlib inline\n",
      "# automatically reload modules on change\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Making discrete and continuous distributions comparable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# figure out for what std the entropy of a Gaussian changes is sign to +\n",
      "dom = np.linspace(0, 1, 10000)\n",
      "\n",
      "for v in dom:\n",
      "    if ss.norm.entropy(loc=0, scale=v) >= 0:\n",
      "        entropy_zero = v\n",
      "        print(\"H(N(0, {})) = {:.3f}\".format(v, float(ss.norm.entropy(loc=0, scale=v))))\n",
      "        print(\"The entropy becomes positive for the std greater than {}\".format(v))\n",
      "        break\n",
      "        \n",
      "for v in dom:\n",
      "    if ss.norm.entropy(loc=0, scale=v) >= 1:\n",
      "        entropy_one = v\n",
      "        print(\"H(N(0, {})) = {:.3f}\".format(v, float(ss.norm.entropy(loc=0, scale=v))))\n",
      "        print(\"The entropy becomes positive for the std greater than {}\".format(v))\n",
      "        break\n",
      "        \n",
      "d = ss.norm(0, entropy_one)\n",
      "print(d.pdf(0))\n",
      "d = ss.norm(0, entropy_one)\n",
      "print(d.pdf(.5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dom = np.linspace(-5, 5, 200)\n",
      "y_gauss = ss.norm.pdf(dom, loc=0, scale=1)\n",
      "\n",
      "dom_entropy = np.linspace(0, 2, 100)\n",
      "e_gauss = [ss.norm.entropy(loc=0, scale=v) for v in dom_entropy]\n",
      "\n",
      "dom = np.linspace(-5, 5, 200)\n",
      "gauss = ss.norm(loc=0, scale=1)\n",
      "\n",
      "y_gauss = gauss.pdf(dom)\n",
      "y_scaled = ss.norm.pdf(dom, 0, 1 * entropy_zero)\n",
      "\n",
      "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
      "\n",
      "ax1.plot(dom, y_gauss, label=\"std=1\")\n",
      "ax1.plot(dom, y_scaled, label=\"sclaed -> H=0\")\n",
      "ax1.plot([-1, 1], [.5, .5], color=\"red\")\n",
      "ax1.plot([-1, -1], [0, .5], color=\"red\")\n",
      "ax1.plot([0, 0], [0, .5], color=\"red\")\n",
      "ax1.plot([1, 1], [0, .5], color=\"red\")\n",
      "\n",
      "ax1.set_title(\"PDF\")\n",
      "ax1.legend()\n",
      "\n",
      "ax2.plot(dom_entropy, e_gauss)\n",
      "ax2.axhline(0, color=\"gray\")\n",
      "ax2.set_title(\"Entropy\")\n",
      "ax2.set_xlabel(\"Std of the Gaussian\")\n",
      "ax2.set_ylabel(\"$H$\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cat_dist = probdist.CategoricalDist({\"a\": 3, \"b\": 0})\n",
      "print(cat_dist.probs())\n",
      "print(cat_dist.H())\n",
      "\n",
      "cat_dist = probdist.CategoricalDist({\"a\": 1, \"b\": 1, \"c\": 1})\n",
      "print(cat_dist.H())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dom = np.linspace(-5, 5, 200)\n",
      "prec = .1\n",
      "scaler = entropy_zero / prec\n",
      "for i in range(1, 10):\n",
      "    sigma = i * scaler\n",
      "    d = ss.norm(0, sigma)\n",
      "    label = \"o={} std={:.2f}; H={:.2f}\".format(i, sigma, float(d.entropy()))\n",
      "    plt.plot(dom, d.pdf(dom), label=label)\n",
      "\n",
      "d = ss.norm(0, prec * scaler)\n",
      "print(d.entropy())\n",
      "plt.plot(dom, d.pdf(dom), label=\"0\")\n",
      "\n",
      "\n",
      "plt.legend();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}